{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T05:58:35.653184Z",
     "start_time": "2018-11-07T05:58:35.649206Z"
    }
   },
   "outputs": [],
   "source": [
    "# Author: Jiechen Wu, David Alfonso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T05:58:35.675086Z",
     "start_time": "2018-11-07T05:58:35.670189Z"
    }
   },
   "outputs": [],
   "source": [
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "\n",
    "def print_red(str):\n",
    "    print(bcolors.FAIL+str+bcolors.ENDC)\n",
    "    \n",
    "def print_green(str):\n",
    "    print(bcolors.OKGREEN+str+bcolors.ENDC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T05:58:35.691027Z",
     "start_time": "2018-11-07T05:58:35.679103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason.wu/miniconda3/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['indices']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T05:58:36.175618Z",
     "start_time": "2018-11-07T05:58:35.694207Z"
    }
   },
   "outputs": [],
   "source": [
    "# cercles data\n",
    "circles_data = np.loadtxt(open('circles.txt','r'))\n",
    "np.random.seed(0)\n",
    "indices = np.random.permutation(len(circles_data[:,-1]))\n",
    "\n",
    "# Separate into train/test as usual\n",
    "circles_train_x = circles_data[indices[:1000],:-1]\n",
    "circles_test_x = circles_data[indices[1000:],:-1]\n",
    "circles_train_y = circles_data[indices[:1000],-1]\n",
    "circles_test_y = circles_data[indices[1000:],-1]\n",
    "# Remap y classes to int 1,2\n",
    "circles_train_y = (circles_train_y+1).astype(int)\n",
    "circles_test_y = (circles_test_y+1).astype(int)\n",
    "\n",
    "\n",
    "# fashion MNIST\n",
    "import utils.mnist_reader as mnist_reader\n",
    "X_train, y_train = mnist_reader.load_mnist('data/fashion', kind='train')\n",
    "X_test, y_test = mnist_reader.load_mnist('data/fashion', kind='t10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T05:59:15.134179Z",
     "start_time": "2018-11-07T05:59:15.112437Z"
    }
   },
   "outputs": [],
   "source": [
    "def rect(x):\n",
    "    return np.maximum(np.zeros(len(x)),x)\n",
    "\n",
    "def softmax(x_v):\n",
    "    sum_exp = np.sum(np.exp(x_v))\n",
    "    return np.exp(x_v)/sum_exp\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self,x,y,dh,m):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.d = len(x)\n",
    "        self.dh = dh # number of hiden layer neurons\n",
    "        self.m = m # m classes\n",
    "        \n",
    "        # hyperparameters\n",
    "        self.lmbd11,self.lmbd12,self.lmbd21,self.lmbd22= 0.1,0.1,0.1,0.1\n",
    "\n",
    "        # Parameter initialization\n",
    "        sqrtr_nc_W1 = 1/self.d**0.5\n",
    "        self.W1 = np.random.uniform(-sqrtr_nc_W1,sqrtr_nc_W1,(self.dh,self.d))\n",
    "        self.b1 = np.zeros(self.dh)\n",
    "        sqrtr_nc_W2 = 1/self.dh**0.5\n",
    "        self.W2 = np.random.uniform(-sqrtr_nc_W2,sqrtr_nc_W2,(self.m,self.dh))\n",
    "        self.b2 = np.zeros(self.m)\n",
    "        self.wb2theta()\n",
    "        self.gradFinitDiff = np.zeros(len(self.theta))\n",
    "\n",
    "    def bprop(self):\n",
    "        model.theta2wb()\n",
    "        self.grad_oa = self.os - np.eye(self.m)[self.y-1]\n",
    "        self.grad_hs = self.W2.T @ self.grad_oa\n",
    "        self.grad_ha = (self.ha>0).astype(int) * self.grad_hs\n",
    "        self.grad_x = self.W1.T @ self.grad_ha\n",
    "        self.grad_b2 = self.grad_oa\n",
    "        self.grad_W2 = np.outer(self.grad_oa, self.hs) \\\n",
    "        +self.lmbd21*np.sign(self.W2)+2*self.lmbd22*self.W2\n",
    "        self.grad_b1 = self.grad_ha\n",
    "        self.grad_W1 = np.outer(self.grad_ha, self.x) \\\n",
    "        +self.lmbd11*np.sign(self.W1)+2*self.lmbd12*self.W1\n",
    "        self.serial_grad()\n",
    "\n",
    "    def fprop(self,ischeck = False, check_theta = None):\n",
    "        if ischeck == False:\n",
    "            theta = self.theta\n",
    "            W1,b1,W2,b2 = self.W1,self.b1,self.W2,self.b2\n",
    "        else:\n",
    "            theta = check_theta\n",
    "            W1,b1,W2,b2 = self.unserial_param(check_theta)\n",
    "        \n",
    "        self.ha = W1@self.x+b1\n",
    "        self.hs = rect(self.ha)\n",
    "        self.oa = W2@self.hs+b2\n",
    "        self.os = softmax(self.oa)\n",
    "        self.L = -np.log(self.os[self.y-1])\n",
    "        self.L_reg = self.L + self.lmbd11*np.sum(np.abs(W1)) \\\n",
    "        + self.lmbd12*np.sum(W1**2) \\\n",
    "        + self.lmbd21*np.sum(np.abs(W2)) \\\n",
    "        + self.lmbd22*np.sum(W2**2) \n",
    "        return self.L_reg\n",
    "        \n",
    "    def serial_param(self,W1,b1,W2,b2):\n",
    "        return np.concatenate([np.ravel(W1),\n",
    "                                     np.ravel(b1),\n",
    "                                     np.ravel(W2),\n",
    "                                     np.ravel(b2)])\n",
    "        \n",
    "    def unserial_param(self,theta):\n",
    "        dh = self.dh\n",
    "        d = self.d\n",
    "        W1 = theta[0:dh*d].reshape((dh,d))\n",
    "        b1 = theta[dh*d:dh*d+dh]\n",
    "        W2 = theta[dh*d+dh:dh*d+dh+m*dh].reshape((m,dh))\n",
    "        b2 = theta[-m:]\n",
    "        return W1,b1,W2,b2\n",
    "    \n",
    "    def wb2theta(self):\n",
    "        self.theta = self.serial_param(self.W1,self.b1,self.W2,self.b2)\n",
    "        \n",
    "    \n",
    "    def theta2wb(self):\n",
    "        self.W1,self.b1,self.W2,self.b2 = self.unserial_param(self.theta)\n",
    "        \n",
    "    def serial_grad(self):\n",
    "        self.gradBprop = np.concatenate([np.ravel(self.grad_W1),\n",
    "                             np.ravel(self.grad_b1),\n",
    "                             np.ravel(self.grad_W2),\n",
    "                             np.ravel(self.grad_b2)])\n",
    "\n",
    "    def cal_finit_difference(self):\n",
    "        epsilon = 10**-5\n",
    "        for ind,t in enumerate(self.theta):\n",
    "            thetaPlus = np.copy(self.theta)\n",
    "            thetaPlus[ind] += epsilon\n",
    "            self.gradFinitDiff[ind] = ((self.fprop(True,thetaPlus)-self.fprop())/epsilon)\n",
    "\n",
    "    def gradient_check(self):\n",
    "        sys_eps = np.nextafter(0, 1)\n",
    "        ratio = (self.gradFinitDiff+sys_eps)/(self.gradBprop+sys_eps)\n",
    "        if np.any(ratio>1.01) or np.any(ratio<0.99):\n",
    "            print_red(\"Gradient check failed.\")\n",
    "            print(\"ratio=\",ratio)\n",
    "        else:\n",
    "            print_green(\"Gradient check succeeded.\")\n",
    "    \n",
    "    def show_two_grads(self):\n",
    "        print(\"Gradient Backprop:\",self.gradBprop)\n",
    "        print(\"Gradient Finit Differenct:\",self.gradFinitDiff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T05:59:15.903603Z",
     "start_time": "2018-11-07T05:59:15.894509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mGradient check succeeded.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dh = 2\n",
    "m = 2\n",
    "model = NeuralNetwork(circles_train_x[0,:],circles_train_y[0],dh,m)\n",
    "model.fprop()\n",
    "model.wb2theta()\n",
    "model.bprop()\n",
    "model.cal_finit_difference()\n",
    "model.gradient_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T05:59:16.996232Z",
     "start_time": "2018-11-07T05:59:16.990457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Backprop: [ 0.34845323 -0.11339211 -0.10652069  0.12420946 -0.27128457 -0.\n",
      " -0.16693179 -0.18456706  0.13623811  0.17374942  0.49925081 -0.49925081]\n",
      "Gradient Finit Differenct: [ 0.34845442 -0.11339106 -0.10651969  0.12421046 -0.2712842   0.\n",
      " -0.16693079 -0.18456606  0.13623911  0.17375042  0.49925206 -0.49924956]\n"
     ]
    }
   ],
   "source": [
    "model.show_two_grads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 & 3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T05:59:20.420053Z",
     "start_time": "2018-11-07T05:59:20.374434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#record: 0\n",
      "\u001b[92mGradient check succeeded.\u001b[0m\n",
      "Gradient Backprop: [-0.10843412  0.17497925  0.12471347  0.18756623 -0.04400905  0.\n",
      " -0.16596074  0.18383367 -0.18381014 -0.15705944  0.49921681 -0.49921681]\n",
      "Gradient Finit Differenct: [-0.10843312  0.17498025  0.12471447  0.18756723 -0.04400904  0.\n",
      " -0.16595974  0.18383467 -0.18380914 -0.15705844  0.49921806 -0.49921556]\n",
      "#record: 1\n",
      "\u001b[92mGradient check succeeded.\u001b[0m\n",
      "Gradient Backprop: [ 0.23524751 -0.22840675 -0.18775093  0.10590428  0.          0.\n",
      " -0.13507412 -0.17294522  0.1521994   0.14786744 -0.5         0.5       ]\n",
      "Gradient Finit Differenct: [ 0.23524851 -0.22840575 -0.18774993  0.10590528  0.          0.\n",
      " -0.13507312 -0.17294422  0.1522004   0.14786844 -0.49999875  0.50000125]\n",
      "#record: 2\n",
      "\u001b[92mGradient check succeeded.\u001b[0m\n",
      "Gradient Backprop: [ 0.39383561  0.56328164  0.18555777 -0.25951742  0.39158395 -0.13273091\n",
      " -0.69420669 -0.22043486  0.36470694 -0.12169572 -0.61302583  0.61302583]\n",
      "Gradient Finit Differenct: [ 0.39383669  0.56328304  0.18555878 -0.25951637  0.39158443 -0.13273086\n",
      " -0.694205   -0.22043385  0.36470862 -0.1216947  -0.61302464  0.61302701]\n",
      "#record: 3\n",
      "\u001b[92mGradient check succeeded.\u001b[0m\n",
      "Gradient Backprop: [-0.21735821 -0.1133703  -0.02605912  0.20293961  0.         -0.2500654\n",
      " -0.15331979 -0.02519826  0.1557976   0.12474744 -0.41578838  0.41578838]\n",
      "Gradient Finit Differenct: [-0.21735721 -0.1133693  -0.02605768  0.20294062  0.         -0.25006496\n",
      " -0.15331879 -0.02519687  0.1557986   0.12474883 -0.41578717  0.4157896 ]\n",
      "#record: 4\n",
      "\u001b[92mGradient check succeeded.\u001b[0m\n",
      "Gradient Backprop: [-0.30019709  0.09508267 -0.49824691  0.10687387  0.17022691  0.39741081\n",
      "  0.3626193   0.3074939   0.0246005  -0.35734315  0.56795381 -0.56795381]\n",
      "Gradient Finit Differenct: [-0.30019602  0.09508367 -0.49824554  0.10687489  0.17022702  0.39741141\n",
      "  0.36262038  0.307495    0.02460158 -0.35734205  0.56795504 -0.56795259]\n",
      "#record: 5\n",
      "\u001b[92mGradient check succeeded.\u001b[0m\n",
      "Gradient Backprop: [ 0.42844292 -0.12441405 -0.2167058  -0.13211752  0.32414599 -0.\n",
      "  0.31655881  0.12212123 -0.30642434  0.23823909  0.54177391 -0.54177391]\n",
      "Gradient Finit Differenct: [ 0.4284442  -0.12441304 -0.2167048  -0.13211652  0.32414644  0.\n",
      "  0.31655991  0.12212223 -0.30642324  0.23824009  0.54177515 -0.54177266]\n",
      "#record: 6\n",
      "\u001b[92mGradient check succeeded.\u001b[0m\n",
      "Gradient Backprop: [ 0.12093937  0.22585064  0.11690671  0.11829046  0.          0.\n",
      " -0.22694817 -0.21198344  0.13236797  0.16551591 -0.5         0.5       ]\n",
      "Gradient Finit Differenct: [ 0.12094037  0.22585164  0.11690771  0.11829146  0.          0.\n",
      " -0.22694717 -0.21198244  0.13236897  0.16551691 -0.49999875  0.50000125]\n",
      "#record: 7\n",
      "\u001b[92mGradient check succeeded.\u001b[0m\n",
      "Gradient Backprop: [-0.17239856  0.23123215  0.156707   -0.35729313  0.          0.18355373\n",
      "  0.14084822 -0.32999309  0.16434127  0.30859574 -0.53011804  0.53011804]\n",
      "Gradient Finit Differenct: [-0.17239756  0.23123315  0.156708   -0.35729198  0.          0.18355388\n",
      "  0.14084922 -0.32999194  0.16434227  0.30859689 -0.5301168   0.53011929]\n",
      "#record: 8\n",
      "\u001b[92mGradient check succeeded.\u001b[0m\n",
      "Gradient Backprop: [-0.19683947 -0.28337159  0.30959322  0.26616904 -0.48293701  0.11415048\n",
      " -0.09943626  0.41190093  0.10735839 -0.45132826  0.48857746 -0.48857746]\n",
      "Gradient Finit Differenct: [-0.19683776 -0.28337052  0.30959426  0.26617004 -0.48293579  0.11415055\n",
      " -0.09943521  0.41190242  0.10735943 -0.45132677  0.48857871 -0.48857621]\n",
      "#record: 9\n",
      "\u001b[92mGradient check succeeded.\u001b[0m\n",
      "Gradient Backprop: [-0.17279316  0.16535511  0.47370903  0.18620898  0.          0.2533822\n",
      " -0.13042523 -0.49435743  0.18329901  0.52207428 -0.57036682  0.57036682]\n",
      "Gradient Finit Differenct: [-0.17279216  0.16535611  0.47371025  0.18621     0.          0.25338244\n",
      " -0.13042423 -0.49435593  0.18330001  0.52207578 -0.5703656   0.57036805]\n"
     ]
    }
   ],
   "source": [
    "# mini batch size\n",
    "K = 10\n",
    "#data_batch = \n",
    "for i in range(K):\n",
    "    print(\"#record:\",i)\n",
    "    model = NeuralNetwork(circles_train_x[i,:],circles_train_y[i],dh,m)\n",
    "    model.fprop()\n",
    "    model.wb2theta()\n",
    "    model.bprop()\n",
    "    model.cal_finit_difference()\n",
    "    model.gradient_check()\n",
    "    model.show_two_grads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "240px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
